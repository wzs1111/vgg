# VGG16
## VGG介绍
采用VGG来完成图像分类任务。VGG采用了较深的网络架构，证明更深的网络结构表现更好，VGG还将测试阶段的三个卷积层替换为了三个全连接层，全连接层可以接受任意大小的输入，从而使模型拥有了可以识别任意尺寸图片的能力，同时使用多个小卷积层代替一个大卷积层，减少计算量，证明了多个小卷积层的叠加比一个大卷积层准确度更高。VGG16的输入大小为224×224的三通道图片，通过两个224×224×64的卷积层和一个大小为112×112×128的池化层，之后再通过4个类似的多个卷积层+池化层架构，之后经过2个大小为1×1×4096和一个大小为1×1×3的全连接层，最后通过softmax函数，输出图片分类结果，每个卷积层和全连接层后跟有线性整流函数（Rectified Linear Unit, ReLU）。
## 运行环境
Python 3.7  

numpy	1.16.2  

tensorflow	1.14.0  

###  

1、read.py:读取cifar-10数据集  

2、tools.py:数据预处理  

3、VGG.py:VGG的主体网络  

4、train.py:进行训练和验证  

## 超参数介绍
### 学习率
是指在优化算法中更新网络权重的幅度大小。学习率可以是恒定的、逐渐降低的，基于动量的或者是自适应的。不同的优化算法决定不同的学习率。当学习率过大则可能导致模型不收敛，损失loss不断上下震荡；学习率过小则导致模型收敛速度偏慢，需要更长的时间训练。通常lr取值为[0.01,0.001,0.0001]
### 批次大小batch_size

批次大小是每一次训练神经网络送入模型的样本数，在卷积神经网络中，大批次通常可使网络更快收敛，但由于内存资源的限制，批次过大可能会导致内存不够用或程序内核崩溃。bath_size通常取值为[16,32,64,128]
### 迭代次数

迭代次数是指整个训练集输入到神经网络进行训练的次数，当测试错误率和训练错误率相差较小时，可认为当前迭代次数合适；当测试错误率先变小后变大时则说明迭代次数过大了，需要减小迭代次数，否则容易出现过拟合。
## 结果
<table>
   <tr>
      <td>学习率</td>
      <td>0.01    </td>
      <td>   0.001</td>
      <td> 0.0001</td>
   </tr>
   <tr>
      <td>准确度/%</td>
      <td>82.69%</td>
      <td>77.80%</td>
      <td>74.47%</td>
   </tr>
</table>

<table>
   <tr>
      <td>迭代次数</td>
      <td>500    </td>
      <td>   1000</td>
      <td>5000</td>
      <td>10000</td>
      <td>20000</td>
   </tr>
   <tr>
      <td>准确度/%</td>
      <td>61.32%</td>
      <td>75.29%</td>
      <td>82.69%</td>
      <td>85.68</td>
      <td>86.07</td>
   </tr>
</table>

<table>
   <tr>
      <td>批次大小</td>
      <td>16    </td>
      <td>   32</td>
      <td> 64</td>
   </tr>
   <tr>
      <td>准确度/%</td>
      <td>82.24%</td>
      <td>82.69%</td>
      <td>81.2500%</td>
   </tr>
</table>

## 分析
(1)当批次大小固定为32，迭代次数为5000时，随着学习率从0.01到0.0001，准确率一直下降，说明学习率为0.01较为合适
(2)当批次大小固定为32，学习率为0.01，迭代次数升高，准确率上升，说明模型还未过拟合
(3)当迭代次数为5000时，学习率为0.01，随着批次大小的升高，准确率一直下降
